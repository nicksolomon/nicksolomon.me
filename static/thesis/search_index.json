[
["index.html", "Local Dependence in Exponential Random Network Models Chapter 1 Introduction 1.1 Random graphs 1.2 Network modeling", " Local Dependence in Exponential Random Network Models Nicholas Solomon May 2017 Chapter 1 Introduction 1.1 Random graphs Figure 1.1: An undirected graph on four vertices. The mathematical object we call a graph is a set of vertices and edges, so for a graph \\(G\\), we write \\(G = (V, E)\\) where \\(V\\) is the set of vertices and \\(E\\) are ordered or unordered pairs \\((i, j)\\) for \\(i, j \\in V\\). These objects can be represented visually by pictures like Figure 1.1. If the pairs in \\(E\\) are ordered, then we say that \\(G\\) is directed (or sometimes that \\(G\\) is a digraph), otherwise we say that \\(G\\) is undirected. The example in Figure 1.1 is undirected; when drawing directed graph, we can indicate the direction of the the edge \\((i, j)\\) by drawing an arrow from node \\(i\\) to node \\(j\\), as in Figure 1.2. If we only consider the presence or absence of an edge between vertices, then we say that the graph \\(G\\) is unweighted. In a weighted graph, each edge is assigned a numeric value, called the weight. The case of an unweighted graph is equivalent a weighted graph where each edge weight \\(w_{ij} \\in \\{0,1\\} \\). Figure 1.2: A directed graph on four vertices Generally, the most convenient way to represent a graph is as an adjacency matrix. For a graph with \\(n\\) vertices, the adjacency matrix is the \\(n \\times n\\) matrix with the weight of edge \\((i,j)\\) in the \\(i, j\\) position. Note that if a graph \\(G\\) is undirected, then its adjacency matrix is symmetric and if \\(G\\) is an unweighted graph, then all its entries are either \\(1\\) or \\(0\\). For example, the graph in Figure 1.1 has adjacency matrix \\[\\begin{equation} \\begin{bmatrix} 0 &amp; 1 &amp; 0 &amp; 1 \\\\ 1 &amp; 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ 1 &amp; 1 &amp; 1 &amp; 0 \\end{bmatrix}. \\tag{1.1} \\end{equation}\\] Here, we have adopted the convention that vertices do not have an edge with themselves, so the diagonal elements of this matrix are all zero. Sometimes we will also represent a graph as an edge list, which is simply the set of pairs in \\(E\\) with their weights. If we assume that a graph \\(G\\) is generated by some kind of stochastic process, then we consider the whole graph as a random variable. This is equivalent to considering the random matrix \\(Y\\), where \\(Y\\) is the adjacency matrix of \\(G\\). We can consider the \\(n^2\\) random variables \\(Y_{ij}\\) for \\(i, j \\in \\{1, \\dots, n\\}\\), taking values in the set of possible weights for the random graph in consideration. For example, if \\(G\\) is an undirected binary random graph, then this can be simplified to the \\(n^2/2 - n\\) Bernoulli random variables \\(Y_{(i, j)}\\) for \\(1 \\leq i \\leq j \\leq n\\). By breaking the random graph into these simpler parts, we can begin to apply familiar statistical ideas to these complex objects. 1.2 Network modeling Graphs are a convenient way to represent relational data, or data that contain information about a relationship between actors. This brings us to the area of network analysis, where random graphs are used to model many different kinds of relationships. For example, in sociology, networks are commonly used to model relationships among people, like marriages within a group of people. Political scientists use random graphs to represent things like the network of trade agreements between nations. Finally, in epidemiology, random networks can model an underlying contact network, say of people who shake hands or otherwise come into contact in a way that could spread a disease, over which a transmissible infection spreads. This allows the researcher to estimate how the medical features of the disease and the sociological features of the population interact to promote or inhibit the spread of disease. As an example of this, see Groendyke, Welch, &amp; Hunter (2012), where, among other things, they examine if closing schools would have had an effect on the spread of an 1861 measles outbreak. To formalize these notions, we begin with a random graph \\(Y\\) on \\(n\\) vertices (called nodes in the field of network analysis) considered as a random matrix with sample space \\(\\mathcal{Y},\\) where \\(\\mathcal{Y}\\) is the set of all possible graphs on \\(n\\) vertices. There may be some restrictions on \\(\\mathcal{Y}\\), depending on the application being considered. Usually, we prohibit edges that connect a vertex to itself by forcing the diagonal entries of \\(Y\\) to be \\(0\\), as in (1.1). However, specific contexts may require nonobvious constraints put in place by the researcher; for example, when using a network to model the romantic relationships within a group of people, the researcher must exclude networks with ties between nodes that do not have the appropriate gender, depending on the respective preferences of each pair of nodes. This thesis explores two classes of network models: the exponential random graph model (ERGM) and the exponential random network model (ERNM). These models are quite similar in that they both model the structural features of the network, such as node degree and triangle formation, as a function of nodal covariates, say age or gender. However, the ERNM also models the effect of network features on the nodes. For example, Fellows &amp; Handcock (2012) show that teens with friends who smoke or drink are more likely to smoke or drink themselves. The notion of local dependence was introduced by Schweinberger &amp; Handcock (2015) in the context of ERGMs. Here we extend this idea to ERNMs and provide new proofs of their two main theorems in this context. The first theorem shows that the stochastic process of sampling smaller subnetworks from a large network satisfies a desirable consistency condition. This means that as we sample larger and larger subnetworks, the model parameter estimates become better and better approximations of the true parameter values. Shalizi &amp; Rinaldo (2013) showed that this is not the case for most ERGMs. The second theorem shows that certain types of statistics of locally dependent random networks have an asymptotically normal distribution, which is also desirable from the point of view of making inferences based on these models. References "],
["2-exponential-random-graph-models.html", "Chapter 2 Exponential random graph models 2.1 Finding parameter estimates 2.2 Examples", " Chapter 2 Exponential random graph models The first model of interest to this thesis is the exponential random graph model (ERGM), introduced by S. Wasserman &amp; Pattison (1996). Broadly, given a network, this model allows us to specify structural features that are of interest and test in a principled way if there are more of those kinds of features present than would be expected if the network were formed by chance. This allows the researcher to draw conclusions about the latent process that generated the network. This model can be expressed by the equation \\[\\begin{equation} P(Y = y | \\theta) = \\frac{e^{\\theta \\cdot g(y)}}{C(\\theta, \\mathcal{Y})} \\tag{2.1}, \\end{equation}\\] where \\(g(y)\\) is a vector of statistics that depend on the network \\(y\\) and \\(\\theta\\) is a vector of parameters. The function \\(C(\\theta, \\mathcal{Y})\\) is a normalizing constant. We may easily extend the model to include nodal covariates (like demographic information) by introducing the fixed \\(n \\times p\\) matrix \\(x\\) which is used to calculate some of the components of \\(g\\). Note that the constant in the denominator depends both on the support of the random variable \\(Y\\), which is fixed and—in principle—known, and the unknown parameter \\(\\theta\\). In general, this constant will have the form \\[\\begin{equation} C(\\theta, \\mathcal{Y}) = \\sum_{y \\in \\mathcal{Y}} e^{\\theta \\cdot g(y)}, \\tag{2.2} \\end{equation}\\] which is impossible to compute in all but the most trivial cases, as the sum is over all possible networks. For the simplest undirected binary network with \\(n\\) nodes, we have \\(\\left| \\mathcal{Y} \\right| = 2^{n(n-1)/2},\\) so for 10 nodes, the constant \\(C\\) will be a sum of \\(2^{45}\\) terms. As each term requires a non-trivial calculation, we are unable to calculate the value of \\(C\\) directly for a network of any reasonable size. With the model in place, we can begin to estimate the parameter \\(\\theta\\) via maximum likelihood estimation. To do that, we define the likelihood function, which takes the parameter space into the reals. Our goal is to find the value of \\(\\theta\\) that maximizes this function given the observed data. We call this \\(\\theta\\) the maximum likelihood estimator, or MLE. Intuitively, we are looking for the value of \\(\\theta\\) that makes the network we have observed most likely according to our model. In our case this function is \\[\\begin{equation} L(\\theta | y) = \\frac{e^{\\theta \\cdot g(y)}}{C(\\theta, \\mathcal{Y})}. \\tag{2.3} \\end{equation}\\] Note that \\(C\\) also varies with \\(\\theta\\). The fact that this term varies with \\(\\theta\\) means that a naive optimization algorithm will be prohibitively slow. Exploring the parameter space almost always involves evaluating the function at many different points. For example, the common gradient descent algorithm involves evaluating the function many times in the neighborhood of a point to approximate the gradient. This then allows the algorithm to choose a new point where the function is larger. This process then repeats. Even when given relatively simple functions, this algorithm can require hundreds of function calls. In our case, that is not feasible, as we cannot even evaluate our function once. 2.1 Finding parameter estimates The intractable normalizing constant (2.2) makes fitting this model directly extremely difficult. With no general analytic method to maximize the likelihood, we must turn to numerical approximations. However, these algorithms involve evaluating \\(L(\\theta)\\) at many different points. When \\(\\theta\\) varies the value of \\(C\\) also changes, so each function evaluation must recompute this enormous sum. This makes standard numerical approaches useless for the problem at hand. Despite this there are several approaches that make use of a variety of approximations to (we hope) find reasonable parameter estimates. Here we will present both frequentist and Bayesian methods for estimating \\(\\theta\\). To begin, we introduce another piece of notation. Definition 2.1 The change statistic is the vector \\[\\begin{equation} \\delta_{g}(y)_{ij} = g(y^{+}_{ij}) - g(y^{-}_{ij}), \\tag{2.4} \\end{equation}\\] where \\(g\\) is the vector of statistics, as before, and \\(y^{+}_{ij}\\) and \\(y^{-}_{ij}\\) are the observed network \\(y\\) with the edge from \\(i\\) to \\(j\\) taken to be present and absent, respectively. Now, we are able to show that, in the case of an unweighted graph \\[ \\operatorname{logit} \\left( P (Y_{ij} = 1 | Y^{c}_{ij} = y^{c}_{ij} ) \\right) = \\theta \\cdot \\delta_{g}(y)_{ij}, \\] where \\(Y^{c}_{ij}\\) is the random variable without considering the tie from \\(i\\) to \\(j\\) and the function \\[ \\operatorname{logit}(x) = \\log \\left(\\frac{x}{1-x}\\right). \\] This follows from noting that \\[\\begin{align*} \\operatorname{logit} \\left[ P(Y_{ij} = 1 | Y^{c}_{ij} = y^{c}_{ij}) \\right] &amp;= \\operatorname{log} \\left[ \\frac{P(Y_{ij} = 1 | Y^{c}_{ij} = y^{c}_{ij})}{1 - P (Y_{ij} = 1 | Y^{c}_{ij} = y^{c}_{ij})} \\right] \\\\ &amp;= \\operatorname{log} \\left[ \\frac{P (Y_{ij} = 1 | Y^{c}_{ij} = y^{c}_{ij})}{P (Y_{ij} = 0 | Y^{c}_{ij} = y^{c}_{ij})} \\right], \\end{align*}\\] as the complement of the set of graphs where \\(Y_{ij} = 1\\) is the set of graphs where \\(Y_{ij} = 1\\). Now, \\[\\begin{align*} \\operatorname{log} \\left[ \\frac{P (Y_{ij} = 1 | Y^{c}_{ij} = y^{c}_{ij})}{P (Y_{ij} = 0 | Y^{c}_{ij} = y^{c}_{ij})} \\right] &amp;=\\operatorname{log}[P (Y_{ij} = 1 | Y^{c}_{ij} = y^{c}_{ij})] - \\operatorname{log}[P (Y_{ij} = 0 | Y^{c}_{ij} = y^{c}_{ij})] \\\\ &amp;= \\operatorname{log}\\left[e^{\\theta \\cdot g(y^{+}_{ij})}\\right] - \\operatorname{log}\\left[e^{\\theta \\cdot g(y^{-}_{ij})}\\right] \\\\ &amp;= \\theta \\cdot \\left( g(y_{ij}^{+}) - g(y_{ij}^{-}) \\right) \\\\ &amp;= \\theta \\cdot \\delta_{g}(y)_{ij}, \\end{align*}\\] as desired. Thus, each component of \\(\\theta\\) represents the increase in the log-odds of a tie from \\(i\\) to \\(j\\) being present in the network that is associated with a change in \\(y^{c}_{ij}\\) that increases the corresponding component of \\(g(y)\\) by one unit. An example of this kind of interpretation is presented in Section 2.2. 2.1.1 Frequentist methods The change statistic allows us to define the pseudolikelihood, introduced by Strauss &amp; Ikeda (1990). The pseudolikelihood function represents the model where the probability that a tie from \\(i\\) to \\(j\\) exists is independent of all the other ties. Even when this assumption is known to be false, the hope is that the maximum pseudolikelihood estimator will be a good approximation of the more general MLE. This yields the likelihood function \\[\\begin{equation*} \\operatorname{PL}(\\theta) = \\prod_{i \\neq j}P(Y_{ij} = y_{ij} | \\theta). \\end{equation*}\\] Taking the logit transforms this into a standard logistic regression where the response variable is the vector containing a 1 or a 0 depending on the existence of the tie between nodes \\(i\\) and \\(j\\) and the explanatory variables are the vectors of change statistics. This can then easily be fit using widely available generalized linear modeling tools. The estimator returned by this logistic regression is called the maximum psuedolikelihood estimator (MPLE). However, this method exhibits a few problems. In many cases, as already discussed, the assumption of dyadic independence is not justifiable, so the coefficient estimates cannot be expected to be accurate in general. The class of models called dyadic independence models are those in which the form of \\(g\\) makes the likelihood exactly equal to the psuedolikelihood, and so we can fit them exactly using this method. When the dyadic independence assumption does not hold, we are no longer maximizing the likelihood associated with our model, so there is no reason to expect that we have the properties that make maximum likelihood estimators so nice. Specifically, there is no reason to believe that the parameter estimates actually asymptotically approach the true values or that the estimates are approximately normally distributed with the reported standard errors. An example of the trouble with standard errors will be seen in Section 2.2. It is clear that a better method for computing the maximum likelihood estimator is highly desirable. This brings us to the Markov chain Monte Carlo MLE (MCMC-MLE) algorithm developed by Geyer &amp; Thompson (1992). They introduce a method with applications to intractable distributions beyond ERGMs, but we will remain within that specific context. The crux of the algorithm lies in choosing a fixed value \\(\\theta_0\\) (typically the MPLE) that we hope is close to the true value of \\(\\theta\\) and then maximizing the likelihood ratio \\[\\begin{equation} \\log \\left[\\frac{L(\\theta)}{L(\\theta_0)} \\right]. \\tag{2.5} \\end{equation}\\] We begin with the log likelihood of model (2.1) \\[\\begin{equation} \\ell(\\theta) = \\theta \\cdot g(y) - \\operatorname{log} \\left( C(\\theta, \\mathcal{Y}) \\right). \\tag{2.6} \\end{equation}\\] We can rewrite the ratio (2.5) as \\[\\begin{equation} \\ell(\\theta) - \\ell(\\theta_{0}) = (\\theta - \\theta_{0}) \\cdot g(y) - \\operatorname{log} \\left( \\frac{C(\\theta, \\mathcal{Y})}{C(\\theta_{0}, \\mathcal{Y})} \\right). \\tag{2.7} \\end{equation}\\] Clearly, this is maximized at the same value of \\(\\theta\\) as the original likelihood, but now we can show that \\[\\begin{equation} \\frac{C(\\theta, \\mathcal{Y})}{C(\\theta_{0}, \\mathcal{Y})} = \\mathbb{E}_{\\theta_0} \\left[ e^{(\\theta - \\theta_0) \\cdot g(y)} \\right]. \\tag{2.8} \\end{equation}\\] This follows from noting that \\[\\begin{align*} \\frac{C(\\theta, \\mathcal{Y})}{C(\\theta_{0}, \\mathcal{Y})} &amp;= \\frac{\\sum_{z \\in \\mathcal{Y}} e^{\\theta \\cdot g(z)}}{\\sum_{w \\in \\mathcal{Y}} e^{\\theta_{0} \\cdot g(w)}} \\\\ &amp;= \\frac{\\sum_{z \\in \\mathcal{Y}} e^{\\theta \\cdot g(z)} e^{(\\theta_0 - \\theta_0) \\cdot g(z)}}{\\sum_{w \\in \\mathcal{Y}} e^{\\theta_{0} \\cdot g(w)}} \\\\ &amp;= \\sum_{z \\in \\mathcal{Y}} \\left[ e^{\\theta \\cdot g(z)} e^{-\\theta_0 \\cdot g(z)} \\left( \\frac{e^{\\theta_0 \\cdot g(z)}}{\\sum_{w \\in \\mathcal{Y}} e^{\\theta_0 \\cdot g(w)}} \\right) \\right]. \\end{align*}\\] Recognizing the term in parentheses as \\(P_{\\theta_0} (Y = z)\\) makes it clear that we have \\[ \\frac{C(\\theta, \\mathcal{Y})}{C(\\theta_{0}, \\mathcal{Y})} = \\sum_{z \\in \\mathcal{Y}} e^{(\\theta - \\theta_0) \\cdot g(z)} P_{\\theta_0} (Y = z) = \\mathbb{E}_{\\theta_0}\\left[ e^{(\\theta - \\theta_{0}) \\cdot g(Y)} \\right], \\] as desired. Now we need only estimate this expectation using the weak law of large numbers. We do this by generating a Markov chain with stationary distribution \\(P_{\\theta_0}\\) and sampling sufficiently many times to get a good approximation of (2.8). Hence, the problem is reduced to constructing a Markov chain with \\(P_{\\theta_0}\\) as its stationary distribution. We use the algorithm developed by Morris, Handcock, &amp; Hunter (2008). It is essentially a Metropolis-Hastings algorithm where the proposal distribution chooses a pair of nodes, also called a dyad, then if they are connected, removes that tie, and if they are not connected, adds a tie between them. The obvious proposal distribution chooses two vertices at random, producing a simple random walk on \\(\\mathcal{Y}\\). As an alternative to this naïve proposal distribution, Morris et al. (2008) and M. S. Handcock et al. (2016) have developed the tie-no-tie, or TNT, proposal distribution. In this method, the dyad is chosen by first selecting whether we will toggle a dyad with or without a tie in the original network. Then a pair of nodes from within the set of those which are either connected or not connected (depending on the previous step) is chosen at random. According to its inventors, this modification of the random walk on \\(\\mathcal{Y}\\) causes the chain to mix better, especially in sparse networks. This allows us to approximate samples from the probability distribution on \\(\\mathcal{Y}\\) implied by the parameter \\(\\theta_0\\). Then we can estimate the expected value in (2.8) and calculate what we hope is a good estimate for the actual MLE. However, this method is not without its caveats. It is shown in Hunter, Handcock, Butts, Goodreau, &amp; Morris (2008) that this algorithm can be sensitive to the initial parameter \\(\\theta_0\\) and a poor choice of this parameter can cause the approximation of the likelihood function (2.7) to never achieve a maximum on the parameter space. This happens when the function that we are optimizing, an approximation of the true log likelihood ratio, is bad enough that it becomes unbounded and so numeric optimization routines fail to find the maximum. 2.1.2 Bayesian methods The parameter \\(\\theta\\) may also be estimated by Bayesian methods. However, this introduces the issue of sampling from a “doubly intractable” posterior distribution, where the problem of incalculable normalizing constants in the posterior is compounded by the functional form of our model (2.1). Markov chain Monte Carlo methods for these distributions have been studied by Murray, Ghahramani, &amp; MacKay (2012), where the easy to implement exchange algorithm was introduced, and Caimo &amp; Friel (2011), where this algorithm was applied to ERGMs. The algorithm very cleverly avoids the intractable constants in (2.1) by augmenting the posterior with an auxiliary variable from the same sample space as the parameter of interest. By doing this in just the right way, we are able to cancel all intractable constants from the acceptance probability (2.10). To be precise, let the observed network \\(y\\) be taken from the distribution \\(P_{\\theta}\\) and let the prior for \\(\\theta\\) have distribution \\(p(\\theta)\\). We must construct a Markov chain with stationary distribution equal to the posterior given by \\[\\begin{equation} \\pi(\\theta | y) = \\frac{P_{\\theta}(Y = y) p(\\theta)}{\\int P_{\\theta}(Y = y) p(\\theta) \\; \\mathrm{d}\\theta}. \\tag{2.9} \\end{equation}\\] In a standard Metropolis-Hastings implementation with proposal distribution =\\(\\theta^{\\prime} \\sim q( \\cdot | \\theta)\\) =500 we would have the acceptance probability \\[\\begin{equation} a = \\min \\left[ 1, \\frac{P_{\\theta^{\\prime}}(Y = y)p(\\theta^{\\prime})q(\\theta^{\\prime}|\\theta)}{P_{\\theta}(Y = y)p(\\theta)q(\\theta|\\theta^{\\prime})} \\right], \\tag{2.10} \\end{equation}\\] where the likelihoods in the numerator and the denominator are evaluated at different values of \\(\\theta\\). For the ERGM, the normalizing constants will not cancel. To get around this, we take \\(w \\sim P_{\\theta^{\\prime}}\\) and \\(\\theta^{\\prime} \\sim q(\\cdot|\\theta)\\). Here, \\(w\\) is another network that we sample from the ERGM distribution with parameter \\(\\theta^{\\prime}\\), while \\(\\theta^{\\prime}\\) is drawn from an arbitrary proposal distribution that can depend on the current value of \\(\\theta\\). Now the distribution we are sampling from is \\[\\begin{equation} \\pi(\\theta, \\theta^{\\prime}, w |y) = \\frac{P_{\\theta}(Y = y) P_{\\theta^{\\prime}}(Y = w) q(\\theta^{\\prime} | \\theta) p(\\theta)}{\\int P_{\\theta}(Y = y) P_{\\theta^{\\prime}}(Y = w) q(\\theta^{\\prime} | \\theta) p(\\theta) \\; \\mathrm{d} \\theta}. \\tag{2.11} \\end{equation}\\] The conditional distribution of \\(\\theta\\) is the posterior we are after. To begin, we draw \\(\\theta^{\\prime}\\) from the (arbitrary) distribution \\(q\\), which can depend on \\(\\theta\\). Then we draw \\(w\\) from the distribution implied by \\(\\theta^{\\prime}\\) (using already developed MCMC routines) and we propose an exchange of the generated data \\(w\\) and the observed data \\(y\\) between the parameters \\(\\theta\\) and \\(\\theta^{\\prime}\\) which is accepted with probability \\[\\begin{equation} a = \\min \\left[ 1, \\frac{P_{\\theta^{\\prime}}(Y = y) P_{\\theta}(Y=w)p(\\theta^{\\prime})q(\\theta^{\\prime}|\\theta)}{P_{\\theta}(Y = y)P_{\\theta^{\\prime}}(Y = w)p(\\theta)q(\\theta|\\theta^{\\prime})} \\right]. \\tag{2.12} \\end{equation}\\] Now all the incalculable constants in (2.12) cancel, and we can approximate the posterior distribution as desired. It was also demonstrated by Caimo &amp; Friel (2011) that in most cases the use of adaptive direction sampling (ADS) allows for a more thorough exploration of the state space in fewer iterations. This improvement involves running multiple chains (say twice as many as the number of parameters in the model) that, at each iteration \\(i\\), are updated separately. When updating the \\(j\\)-th chain, two other chains, \\(k\\) and \\(\\ell\\) are randomly selected, then we propose \\(\\theta_{j}^{\\prime} = \\gamma (\\theta^{i}_{k} - \\theta^{i}_{\\ell}) + \\epsilon\\) where \\(\\gamma\\) is a fixed tuning parameter and \\(\\epsilon\\) is a small random quantity, both chosen to achieve a higher level of mixing than is usually seen when running a single chain in isolation. This improves the overall mixing of the separate chains and allows the process to thoroughly explore the sample space in fewer iterations. This is the default method in the Bergm package. 2.2 Examples Figure 2.1: A plot of the Florentine marriage network where node size indicates wealth in thousands of lira. For illustrative purposes, we will use the Florentine wedding data included in the R ergm package by M. S. Handcock et al. (2016), which we also use to fit MPLE and MCMC-MLE models. We will use the Bergm package by Caimo &amp; Friel (2014) to fit the Bayesian models. These data consist of an undirected network of marriages between Florentine families during the Renaissance, along with several nodal covariates, including the family wealth in thousands of lira in the year 1427. This network is drawn in Figure 2.1. We will fit the ERGM with network statistics \\[\\begin{equation} g(y) = \\left( \\sum_{i &lt; j} y_{ij}, \\sum_{i &lt; j &lt; k} y_{ij} y_{jk} y_{ki}, \\sum_{i &lt; j} y_{ij} \\left| x_{i} - x_{j} \\right| \\right), \\tag{2.13} \\end{equation}\\] where \\(y\\) is the network and \\(x\\) is the corresponding vector of wealth measurements. Simply put, this creates a term for the number of edges, the number of triangles, and the difference in wealth between connected nodes in the network. The edge term acts as a sort of intercept in the model by measuring the overall propensity of actors to form ties, the triangle term measures the propensity of actors in the graph to form triangles, and the wealth difference term accounts for how difference in family fortune affects the probability of tie formation. Tables 2.1, 2.2, and 2.3 show the coefficient estimates and standard errors. Bayesian estimation is done using a very flat multivariate normal prior centered on the origin with variance-covariance matrix \\[\\begin{equation*} \\Sigma = \\begin{bmatrix} 100 &amp; 0 &amp; 0 \\\\ 0 &amp; 100 &amp; 0 \\\\ 0 &amp; 0 &amp; 100 \\\\ \\end{bmatrix}. \\end{equation*}\\] Figure 2.2 shows posterior density estimates for the Bayesian model. Table 2.1: The results of fitting model using MPLE. term estimate std.error edges -2.36 0.44 triangle 0.16 0.44 absdiff.wealth 0.02 0.01 Table 2.2: The results of fitting model using MCMC-MLE. term estimate std.error edges -2.29 0.45 triangle -0.04 0.60 absdiff.wealth 0.02 0.01 Table 2.3: The results of fitting model using Bayesian methods. term posterior mean posterior s.d. edges -2.25 0.45 triangle -0.33 0.59 absdiff.wealth 0.02 0.01 Figure 2.2: Posterior density plots of the Florentine marriage model parameter estimates. Figure 2.3: Goodness-of-fit assessment for the Bayesian model fit to the Florentine marriage data. These plots compare simulated distributions of graph statistics that were not modeled to the observed values (in red). We can see that all of these methods produce similar outcomes, with a clearly nonzero edge term, which makes sense as this is akin to an intercept term in a standard linear model, and a small but significant term corresponding to the difference in wealth. Notice that the standard error of the triangle term (which creates dependence between dyads) is much larger when the model is fit using MCMC-MLE. This supports the notion that standard errors reported my MPLE are unreliable in dyadic dependence models, as was discussed in Section 2.1.1. Interpreting these coefficients allows us to infer that a difference in wealth of 1 unit (in this case 1000 lira), changes the log-odds of forming a tie (according to the MCMC-MLE model) by a factor of \\(\\theta_3 \\approx\\) -0.04. The ergm and Bergm packages also provide tools for assessing the goodness-of-fit of exponential random graph models. These tools simulate many networks from the distribution implied by the model with the parameter estimate and then compare the distributions of several network statistics that were not modeled to the observed network. These statistics are by default minimum geodesic distance, edgewise shared partners, and degree distribution. Figure 2.3 shows plots of these comparisons for the Bayesian model. As we can see, our model matches the simulated distributions fairly well. References "],
["3-locally-dependent-exponential-random-network-models.html", "Chapter 3 Locally dependent exponential random network models 3.1 Definitions and notation 3.2 Preliminary theorems 3.3 Consistency under sampling 3.4 Asymptotic normality of statistics", " Chapter 3 Locally dependent exponential random network models Figure 3.1: A locally dependent random network with neighborhoods \\(A_1, A_2, \\dots, A_K\\) and two binary node attributes, represented as gray or black and circle or diamond. To begin, we define a random network, developed by Fellows &amp; Handcock (2012). By way of motivation, note that in the ERGM the nodal variates are fixed and are included in the model as explanatory variables in making inferences about network structure. Furthermore, there is a class of models that we do not discuss here that consider the network as a fixed explanatory variable in modeling (random) nodal attributes. It is not difficult to come up with situations where a researcher would like to jointly model both the network and the node attributes. Thus we define a class of networks in which both the network structure and the attributes of the individual nodes are modeled as random quantities. Definition 3.1 (Random network) Let \\(\\mathcal{N}\\) be a countable collection of nodes (which we take to be a subset of \\(\\mathbb{N}\\)). Let \\(Y\\) be the random graph on the nodes \\(\\mathcal{N}\\) with support \\(\\mathcal{Y}\\). Then for each element \\(n \\in \\mathcal{N}\\), let there be a corresponding random vector of node attributes \\(X_n \\in \\mathbb{R}^q\\) and collect them into the \\(n \\times q\\) random matrix \\(X\\) with support \\(\\mathcal{X}\\). The is the random variable \\(Z = (Y, X)\\) with support \\(\\mathcal{Z} = \\mathcal{Y} \\times \\mathcal{X}\\). Now we wish to model these objects, so we follow the ERGM and turn to the exponential family (Fellows &amp; Handcock, 2012). We write \\[\\begin{equation} P(Y = y, X = x| \\eta) \\propto e^{\\eta \\cdot g(y, x)}. \\tag{3.1} \\end{equation}\\] This looks very similar to the ERGM, but note the explicit dependence on the quantity \\(x\\). More concretely, we can include terms that depend only on \\(x\\), which would have no place in an ERGM. We can further express the difference of the two models by rewriting the left hand side of as \\[\\begin{equation*} P(X = x, Y = y | \\eta) = P(Y = y|X = x, \\eta)P(X=x|\\eta), \\end{equation*}\\] where the first term on the right hand side is the ERGM and the second term is \\[\\begin{equation*} P(X = x|\\eta) = \\frac{C(\\mathcal{Z}, \\eta, x)}{C(\\mathcal{Z}, \\eta)}, \\end{equation*}\\] where \\[\\begin{equation*} C(\\mathcal{Z}, \\eta, x) = \\int_{\\{(v, u) \\in \\mathcal{Z} : u = x\\}} P(X = x | \\eta). \\end{equation*}\\] Roughly, this is the proportion of the total sample space \\(\\mathcal{Z}\\) that is possible with \\(x\\) fixed. This is not, in general, equal to one, so the ERNM is not equal to the ERGM (Fellows &amp; Handcock, 2012). 3.1 Definitions and notation We will consistently refer to a set of nodes, \\(A_{k}\\), as the \\(k\\)-th neighborhood, with an uppercase \\(K\\) representing the total number of neighborhoods and a lowercase \\(k\\) representing a specific neighborhood. The variable \\(\\mathcal{N}\\) will refer to the domain of a random network, usually the union of a collection of neighborhoods. Nodes within the network will be indexed by the variables \\(i\\) and \\(j\\), with \\(Z_{ij} = (\\{Y_{ij}, X_i, X_j\\})\\), where \\(Y_{ij}\\) is referring to the edge between nodes \\(i\\) and \\(j\\), and \\(X_{i}\\) and \\(X_j\\) refer to the random vectors of node attributes. Abstracting this further, \\(i\\) and \\(j\\) will also refer to tuples of nodes, so we will write \\(\\vec{i} = (i_1, i_2, \\dots, i_q) \\in \\mathcal{N} \\times \\mathcal{N} \\times \\dots \\times \\mathcal{N}\\). The variables \\(Z\\) and \\(Y\\) will also often carry a subscript of \\(W\\) or \\(B\\) (for example \\(Y_{Bij}\\)) which emphasizes that the edge from \\(i\\) to \\(j\\) is within or between neighborhoods, respectively. Finally, for lack of a better notation, the indicator function \\(\\mathbb{I}_{B}(i,j)\\) (where \\(B\\) is for between) is one if \\(i \\in A_{l}\\) and \\(j \\in A_{p}\\) where \\(l \\neq p\\), and zero otherwise. Definition 3.2 (Local dependence property) Extending the definition in Schweinberger &amp; Handcock (2015), a random network model satisfies if there is a partition of the node set \\(\\mathcal{N}\\) into neighborhoods \\(A_1, A_2, \\dots, A_K\\) for \\(K \\geq 2\\) such that the network variables \\(Z_{ij}\\) are dependent when \\(i, j \\in A_{\\ell}\\) for some \\(\\ell\\) and independent otherwise. We also require that nodal attributes depend only on the attributes of nodes within the same neighborhood. Thus, the probability measure can be written as \\[\\begin{equation} P(Z \\in \\mathbf{Z}) = \\prod_{k = 1}^{K}\\left[ P_{kk}(Z_{kk} \\in \\mathbf{Z}_{kk}) \\prod_{\\ell = 1}^{k-1} P_{kl}(Z_{kl} \\in \\mathbf{Z}_{kl}, Z_{lk} \\in \\mathbf{Z}_{lk}) \\right], \\end{equation}\\] where \\(Z_{mn}\\) is the subnetwork consisting of the random graph ties from nodes in \\(A_m\\) to those in \\(A_n\\) and the appropriate node variables and \\(\\mathbf{Z}_{mn}\\) is a subset of the sample space of \\(Z_{mn}\\). Furthermore, the measures \\(P_{kk}\\) can induce dependence between dyads while the measures \\(P_{kl}\\) induce independence. Definition 3.3 (Sparsity) Also from Schweinberger &amp; Handcock (2015), we say a locally dependent random network is if there is some \\(\\delta &gt; 0\\) and some \\(C &gt; 0\\) such that \\[\\begin{equation} \\mathbb{E}\\left( \\left| Y_{Bij} \\right|^{p} \\right) \\leq Cn^{-\\delta}, \\qquad (p = 1, 2) \\end{equation}\\] where \\(n = |\\mathcal{N}|\\) and \\(Y_{Bij}\\) signifies the tie between neighborhoods from node \\(i \\in A_{l}\\) to node \\(j \\in A_{m}\\) where \\(l \\neq m\\). 3.2 Preliminary theorems In proving our theorems, we will make use of several other central limit theorems, all of which can be found in Billingsley (1995). The first is the Lindeberg-Feller central limit theorem for triangular arrays. The second is Lyapounov’s condition, which gives a convenient way to show that the Lindeberg-Feller theorem holds. Finally, we make use of a central limit theorem for dependent random variables. For the sake of brevity, in this section we state each of these without proof. Theorem 3.1 (Billingsley, 1995 Theorem 27.2) For each \\(n\\) take \\(X_{n1}, \\dots, X_{nr_n}\\), independent with \\(\\mathbb{E}(X_{ns}) = 0\\) for all \\(n\\) and \\(s\\) (where no generality is lost in this assumption). Then we have \\(\\sigma^{2}_{ns} = \\operatorname{Var}(X_{ns}) = \\mathbb{E}(X_{ns}^2)\\). Next, set \\(s^{2}_{s} = \\sum_{s = 1}^{r_n} \\sigma^{2}_{ns}\\). Now set \\[\\begin{equation*} S_{n} = X_{n1} + \\dots + X_{nr_n}. \\end{equation*}\\] If the , \\[\\begin{equation} \\lim_{n \\to \\infty} \\sum_{s = 1}^{r_n} \\frac{1}{s^{2}_{n}} \\int_{|X_{ns} \\geq \\epsilon s_n} X^{2}_{ns} = 0 \\end{equation}\\] holds for all \\(\\epsilon &gt; 0\\), then \\(S_n \\xrightarrow{\\mathrm{d}} N(0,1)\\). Theorem 3.2 (Billingsley, 1995 Theorem 27.3) Let \\(S_n\\) be as before. Then if , \\[\\begin{equation} \\lim_{n \\to \\infty} \\sum_{s = 1}^{r_n} \\frac{1}{s_n^{2 + \\delta}} \\mathbb{E} \\left( \\left| X_{ns} \\right|^{s + \\delta} \\right) = 0 \\tag{3.2} \\end{equation}\\] holds for some \\(\\delta &gt; 0\\), then the Lindeberg condition also holds. Therefore \\(S_{n} \\xrightarrow{\\mathrm{d}} N(0,1)\\). Theorem 3.3 (Billingsley, 1995 Theorem 27.4) Suppose that \\(X_1, X_2, \\dots\\) is stationary and \\(\\alpha\\)-mixing with \\(\\alpha_n = O(n^{-5})\\) and that \\(\\mathbb{E}(X_n) = 0\\) and \\(\\mathbb{E}(X_n^{12}) &lt; \\infty\\). Note that the condition on \\(\\alpha\\) is stronger than what we require. Our \\(X_n\\) will be \\(M\\)-dependent, meaning that each \\(X_n\\) is independent of all \\(X_m\\) where \\(|n - m| &gt; M\\). It is true that an \\(M\\)-dependent sequence is \\(\\alpha\\)-mixing for constant \\(\\alpha\\). Then, if \\(S_n = X_1 + \\dots X_n\\), we have \\[\\begin{equation} \\frac{\\operatorname{Var}(S_n)}{n} \\to \\sigma^2. \\end{equation}\\] Then, if \\(\\sigma &gt; 0\\), we have \\(S_n \\xrightarrow{\\mathrm{d}} N(0,1)\\). The final theorem is Slutsky’s theorem, a classic result of asymptotic theory in statistics. Theorem 3.4 (Wasserman, 2004 Theorem 5.5) Let \\(X_n, X, Y_n\\) be random variables and let \\(c\\) be a constant. Then, if \\(X_n \\xrightarrow[]{\\mathrm{d}} X\\) and \\(Y \\xrightarrow[]{\\mathrm{p}} c\\) we have \\(X_n + Y_n \\xrightarrow[]{\\mathrm{d}} X + c\\) and \\(X_n Y_n \\xrightarrow[]{\\mathrm{d}} cX\\). 3.3 Consistency under sampling With these in place, we attempt to extend a result about locally dependent ERGMs proven by Schweinberger &amp; Handcock (2015) to locally dependent ERNMs. In short, this theorem states that the parameters estimated by modeling a small sample of a larger network can be generalized to the overall network. It was shown by Shalizi &amp; Rinaldo (2013) that most useful formulations of ERGMs do not form projective exponential families in the sense that the distribution of a subgraph cannot be, in general, recovered by marginalizing the distribution of a larger graph with respect to the edge variables not included in the smaller graph. Hence, we are unable to generalize parameter estimates from the subnetwork to the total network. To show that locally dependent ERNMs do form a projective family, let \\(\\mathbb{A}\\) be a collection of sets \\(\\mathcal{A}\\), where each \\(\\mathcal{A}\\) is a finite collection of neighborhoods. Also, allow the set \\(\\mathbb{A}\\) to be an ideal, so that if \\(\\mathcal{A} \\in \\mathbb{A}\\), every subset of \\(\\mathcal{A}\\) is also in \\(\\mathbb{A}\\) and if \\(\\mathcal{B} \\in \\mathbb{A}\\), then \\(\\mathcal{A} \\cup \\mathcal{B} \\in \\mathbb{A}\\). If \\(\\mathcal{A} \\subset \\mathcal{B}\\), think of passing from the set \\(\\mathcal{A}\\) to the set \\(\\mathcal{B}\\) as taking a larger sample of the (possibly infinite) set of neighborhoods in the larger network. Then let \\(\\{\\mathcal{P}_{\\mathcal{A}, \\theta}\\}_{\\mathcal{A} \\in \\mathbb{A}}\\) be the collection of ERNMs with parameter \\(\\theta\\) indexed by the sets in \\(\\mathbb{A}\\). For each \\(\\mathcal{A} \\in \\mathbb{A}\\), let \\(\\mathcal{P}_{\\mathcal{A}, \\Theta} = \\{P_{\\mathcal{A}, \\theta}\\}_{\\theta \\in \\Theta}\\) be the collection of ERNMs on the neighborhoods in \\(\\mathcal{A}\\) with parameter \\(\\theta \\in \\Theta\\) where \\(\\Theta \\subset \\mathbb{R}^{p}\\) is open. Assume that each distribution in \\(\\mathcal{P}_{\\mathcal{A}, \\Theta}\\) has the same support \\(\\mathcal{Z}_{\\mathcal{A}}\\) and that \\(\\mathcal{A} \\subset \\mathcal{B}\\) if and only if \\(\\mathcal{Z}_{\\mathcal{B}} = \\mathcal{Z}_{\\mathcal{A}} \\times \\mathcal{Z}_{\\mathcal{B} \\setminus \\mathcal{A}}\\). Then, the exponential family \\(\\{\\mathcal{P}_{\\mathcal{A}, \\Theta}\\}_{\\mathcal{A} \\in \\mathbb{A}}\\) is projective in the sense of Shalizi &amp; Rinaldo (2013 Definition 1) precisely when Theorem 3.6 holds. This follows from a specific case of the general definition given by Shalizi &amp; Rinaldo (2013). There, for every pair \\(\\mathcal{A}\\) and \\(\\mathcal{B}\\) with \\(\\mathcal{A} \\subset \\mathcal{B}\\), they define the natural projection mapping \\(\\pi_{\\mathcal{B} \\to \\mathcal{A}}: \\mathcal{Z_B} \\to \\mathcal{Z_A}\\). Informally, this mapping projects the set \\(\\mathcal{Z_B}\\) down to \\(\\mathcal{Z_A}\\) by simply removing the extra data. For example if \\(\\mathcal{B} = \\{A_1, A_2\\}\\) and \\(\\mathcal{A} = \\{A_1\\}\\) as in Figure 3.1, then the mapping \\(\\pi_{\\mathcal{B} \\to \\mathcal{A}}\\) is shown in Figure 3.2. Figure 3.2: The projection mapping from \\(\\mathcal{B} = \\{A_1, A_2\\}\\) to \\(\\mathcal{A} = \\{A_1\\}\\). This is desirable because Shalizi &amp; Rinaldo (2013) have demonstrated the following theorem. Theorem 3.5 (Shalizi &amp; Rinaldo, 2013 Theorem 3) If the exponential model family \\(\\{\\mathcal{P}_{\\mathcal{A} \\Theta}\\}_{\\mathcal{A} \\in \\mathbb{A}}\\) is projective and the log of the normalizing constant can be written as \\[\\begin{align} \\begin{split} \\log \\left( C(\\theta, \\mathcal{Z}) \\right) &amp;= \\log \\left( \\int_{\\mathcal{Z}} e^{\\theta \\cdot g(z)} \\;\\mathrm{d}z \\right) \\\\ &amp;= r \\left(\\left| \\mathcal{Z} \\right| \\right) a(\\theta), \\end{split} \\end{align}\\] where \\(r\\) is a positive, monotone increasing function of some positive measure on \\(\\mathcal{Z}\\) and \\(a\\) is a differentiable function of \\(\\theta\\), then the maximum likelihood estimator exists and is strongly consistent, meaning that the MLE, \\(\\hat{\\theta} \\xrightarrow[]{\\text{a.s.}} \\theta\\), where \\(\\theta\\) is the unknown parameter being estimated. This is trivially achieved by setting \\(r = 1\\) for all values of \\(\\left| \\mathcal{Z} \\right|\\) and setting \\(a(\\theta) = \\log(C(\\theta, \\mathcal{Z}))\\). We have differentiability of \\(a\\) with respect to \\(\\theta\\) by a result from multivariable calculus that follows from Fubini’s theorem. From a practical perspective, this means that a researcher using this model can assume that parameters estimated from samples of a large network are increasingly good approximations for the true parameter values as the sample size increases. Theorem 3.6 Let \\(A_{1}, A_{2}, \\dots\\) be a sequence of neighborhoods and define the sequence \\(\\{\\mathcal{N}_{K}\\} = \\bigcup_{i = 1}^{K} A_{i}\\). Then let \\(Z_{1}, Z_{2}, \\dots\\) be the sequence of locally dependent random networks on the \\(\\mathcal{N}_K\\). For each \\(Z_K\\), there is the corresponding set of neighborhoods \\(\\mathcal{A}_K\\). Let \\(P_K\\) be a generic probability distribution from the family \\(\\{\\mathcal{P}_{K \\theta}\\}_{\\theta \\in \\Theta}\\). Let the network \\[\\begin{equation*} \\pi_{\\mathcal{A}_{K+1} \\to \\mathcal{A}_K}(Z_{K+1}) = Z_{K+1 \\setminus K}, \\end{equation*}\\] with corresponding distirbution \\(P_{K+1 \\setminus K}\\). Then \\[\\begin{equation} P_{K}(Z_{K} \\in \\mathbf{Z}_K) = P_{K+1}(Z_{K} \\in \\mathbf{Z}_K, Z_{K+1 \\setminus K} \\in \\mathcal{Z}_{K+1 \\setminus K}), \\end{equation}\\] my_dev where \\(\\mathcal{Z}_K\\) is the sample space of the distribution \\(P_{K}\\) and \\(\\mathbf{Z}_K \\subset \\mathcal{Z}_K\\). This is a specific case of the definition of projectibility for a general exponential family given by Shalizi &amp; Rinaldo (2013). Proof. This follows from the definition of local dependence, in much the same way as the proof for ERGMs by Schweinberger &amp; Handcock (2015) does. We have \\[\\begin{align*} P_{K+1}(Z_{K} \\in \\mathbf{Z}_K, Z_{K+1 \\setminus K} \\in \\mathcal{Z}_{K+1 \\setminus K}) &amp;= P_{K+1}(Z_{K} \\in \\mathbf{Z}_K) P_{K+1 \\setminus K}(Z_{K+1 \\setminus K} \\in \\mathcal{Z}_{K+1 \\setminus K}) \\\\ &amp;= P_{K}(Z_{K} \\in \\mathbf{Z}_K) (1) \\\\ &amp;= P_{K}(Z_{K} \\in \\mathbf{Z}_K), \\end{align*}\\] where the measure becomes \\(P_k\\) from the product definition of a locally dependent random network. 3.4 Asymptotic normality of statistics In this section we will prove that certain classes of statistics of locally dependent random networks are asymptotically normally distributed as the number of neighborhoods tends to infinity. The statistics we consider can be classified into three types: first, statistics which depend only on the graph structure; second, statistics that depend on both the graph and the nodal variates; and third, statistics that depend only on the nodal variates. The first class of statistics has already been considered by Schweinberger &amp; Handcock (2015), but we will reproduce the proof here, as the second proof is very similar. The third class of statistics becomes normal in the limit by a central limit theorem for \\(M\\) dependent random variables in Billingsley (1995). Before we begin to explicitly define each of these classes, we clarify the notation that will be used. A general statistic will be a function \\[\\begin{equation*} S:\\mathcal{N}^d \\to \\mathbb{R}, \\end{equation*}\\] where \\(\\mathcal{N}^d\\) is the \\(d\\)-fold Cartesian product of the set of nodes, \\(\\mathcal{N}\\), with itself: \\[\\begin{equation*} \\mathcal{N}^d = \\underbrace{\\mathcal{N} \\times \\dots \\times \\mathcal{N}}_{d \\text{ times}}. \\end{equation*}\\] Additionally, the statistic will often carry a subscript \\(K\\), indicating that the statistic is of the random network with \\(K\\) neighborhoods. Formally, as explained in Schweinberger &amp; Handcock (2015), the first class of statistics contains those that have the form \\[\\begin{equation*} S_{K} = \\sum_{i \\in \\mathcal{N}^d} S_{Ki}, \\end{equation*}\\] where \\[\\begin{equation*} S_{Ki} = \\prod_{l, p \\in i} Y_{lp}, \\end{equation*}\\] a product \\(q\\) of edge variables that captures the interaction desired. We will also make use of the set \\(A_k^d,\\) wich is a similar cartesian product. When we write \\(i \\in A_k^d\\), we mean the every component of the \\(d\\)-tuple \\(i\\) is an element of \\(A_k\\). Furthermore, by a catachrestic abuse of notation, we will write \\(l, p \\in i\\) to mean that \\(l\\) and \\(p\\) are vertices contained in the \\(d\\)-tuple \\(i\\). Now we are ready to prove the first case of the theorem. Theorem 3.7 Let \\(A_1, A_2, \\dots, A_K\\) be a sequence of neighborhoods of size at most \\(M\\) and form the sequence of domains \\(\\mathcal{N}_{K} = \\bigcup_{k = 1}^{K} A_{k}\\). Then let \\(Z_{1}, Z_{2}, \\dots, Z_{K}\\) be the sequence of unweighted random networks on the \\(\\mathcal{N}_{K}\\). Then, let the statistic \\(S_{K}:\\mathcal{N}_{K}^d \\to \\mathbb{R}\\) be given. Furthermore, assume the statistic depends only on the graph variables of the \\(Z_{K}\\). We also assume that the \\(Z_{K}\\) satisfy the local dependence property and that they are \\(\\delta\\)-sparse, for some \\(\\delta &gt; d\\). Finally, we require that \\(\\operatorname{Var}(W^{\\ast}_{K}) \\to \\infty\\), where \\(W^{\\ast}_{K}\\) is defined in (3.3). Then \\[\\begin{equation} \\frac{S_K - \\mathbb{E}(S_K)}{\\sqrt{Var(S_{K})}} \\xrightarrow[K \\to \\infty]{\\mathrm{d}} N(0, 1). \\end{equation}\\] Proof. As the networks \\(Z_K\\) are unweighted, all edge variables \\(Y_{ij}\\in \\{0, 1\\}\\). Let \\(\\mu_{ij} = \\mathbb{E}(Y_{ij})\\). Then define \\(V_{ij} = Y_{ij} - \\mu_{ij}\\). Therefore, without loss of generality, we may work with \\(V_{ij}\\), which has the convenient property that \\(\\mathbb{E}(V_{ij}) = 0\\). This means that we can similarly shift our statistics of interest, \\(S_K\\). Therefore, call \\(S_K^{\\ast} = S_{K} - \\mathbb{E}(S_K)\\), so that \\(\\mathbb{E}(S_K^{\\ast}) = 0\\). Note that we can write \\[\\begin{equation*} S^{\\ast}_{K} = W^{\\ast}_{K} + B^{\\ast}_{K}, \\end{equation*}\\] with \\[\\begin{equation} W^{\\ast}_{K} = \\sum_{k = 1}^{K} W^{\\ast}_{K,k} = \\sum_{k = 1}^{K} \\sum_{i \\in \\mathcal{N}_{K}^d} \\mathbb{I}(i\\in A_{k}^d) S^{\\ast}_{Ki} \\tag{3.3} \\end{equation}\\] and \\[\\begin{equation} B^{\\ast}_{K} = \\sum_{i \\in \\mathcal{N}_{K}^d} \\mathbb{I}_{B}(i) S^{\\ast}_{Ki}, \\end{equation}\\] where the indicator functions restrict the sums to within the \\(k\\)-th neighborhood and between neighborhoods of the graph, respectively. Specifically, \\(\\mathbb{I}_{B}(i) = 1\\) when the \\(d\\)-tuple of nodes \\(i\\) contains nodes from different neighborhoods, or exactly when \\(\\mathbb{I}(i \\ in A_{k}^d) = 0\\) for all neighborhoods \\(k\\). By splitting the statistic into the within and between neighborhood portions, we are able to make use of the independence relation between edges that connect neighborhoods. We also have \\(\\mathbb{E}(W^{\\ast}_{K}) = 0\\) and \\(\\mathbb{E}(B^{\\ast}_{K}) = 0\\), as each quantity is a sum of random variables with mean zero. The idea of this proof is to gain control over the variances of \\(B^{\\ast}_{K}\\) and all the elements of the sequence \\(W^{\\ast}_{Kk}\\). We can then show that \\(B^{\\ast}_{K}\\) is converging in probability to zero and that the triangular array \\(W^{\\ast}_{K}\\) satisifies Lyaponouv’s condition, and is thus asymptotically normal. Finally, Slutsky’s theorem allows us to extend the result to \\(S^{\\ast}_{K}\\). To bound the variance of \\(B^{\\ast}_{K}\\), note that \\[\\begin{equation*} \\operatorname{Var}(B^{\\ast}_{K}) = \\sum_{i \\in \\mathcal{N}_{K}^d} \\sum_{j \\in \\mathcal{N}_{K}^d} \\mathbb{I}_{B}(i) \\mathbb{I}_{B}(j) \\operatorname{Cov}(S^{\\ast}_{Ki}, S^{\\ast}_{Kj}). \\end{equation*}\\] Despite independence, some of these covariances may be nonzero if the two terms of the statistic both involve the same edge. For example, in Figure , a statistic that counted the number of edges between gray nodes plus the number of edges between diamond shaped nodes would have a nonzero covariance term because of the edge between the two nodes that are both gray and diamond shaped. To show that, in the limit, these covariances vanish, we need only concern ourselves with the nonzero terms in the sum. That is, only those terms where \\(\\mathbb{I}_{B}(i) \\mathbb{I}_{B}(j) = 1\\). This happens exactly when both \\(S^{\\ast}_{Ki}\\) and \\(S^{\\ast}_{Kj}\\) involve a between neighborhood edge variable. So, note that we have \\[\\begin{align} \\begin{split} \\operatorname{Cov}(S^{\\ast}_{Ki}, S^{\\ast}_{Kj}) &amp;= \\mathbb{E}(S^{\\ast}_{Ki} S^{\\ast}_{Kj}) - \\mathbb{E}(S^{\\ast}_{Ki}) \\mathbb{E}(S^{\\ast}_{Kj}) \\\\ &amp;= \\mathbb{E}(S^{\\ast}_{Ki}S^{\\ast}_{Kj}), \\end{split} \\end{align}\\] as the expectation of each term is zero. Next we take \\(Y_{l_1 l_2}\\) to be one of the (possibly many) between neighborhood edge variables in this product (such that \\(\\mathbb{I}_B(i) = 1\\) where \\(i\\) is any tuple containing \\(l_1\\) and \\(l_2\\)) and \\(V_{l_1 l_2}\\) to be the recentered random variable corresponding to \\(Y_{l_1 l_2}\\). Then, \\[\\begin{align*} \\operatorname{Cov}(S^{\\ast}_{Ki}, S^{\\ast}_{Kj}) &amp;= \\mathbb{E}\\left( \\prod_{m,n \\in i} V_{mn} \\prod_{m,n \\in j} V_{mn} \\right) \\\\ &amp;= \\mathbb{E}\\left( V_{l_1 l_2}^p \\prod_{m,n \\in (i \\cup j) \\setminus \\{l_1, l_2\\}} V_{mn} \\right), &amp; (p = 1,2) \\end{align*}\\] where we must consider the case where \\(p = 1\\) to account for the covariance of \\(S^{\\ast}_{Ki}\\) and \\(S^{\\ast}_{Kj}\\) when \\(i \\neq j\\) and the case where \\(p = 2\\) to account for the variance of \\(S^{\\ast}_{Ki}\\), which is computed in the case where \\(i = j\\). So, if \\(p = 1\\), then \\[\\begin{align*} \\mathbb{E}\\left( V_{l_1 l_2} \\prod_{m,n \\in (i \\cup j) \\setminus \\{l_1, l_2\\}} V_{mn} \\right) &amp;= \\mathbb{E}\\left( V_{l_1 l_2}\\right) \\mathbb{E}\\left( \\prod_{m,n \\in (i \\cup j) \\setminus \\{l_1, l_2\\}} V_{mn} \\right) \\\\ &amp;= 0, \\end{align*}\\] by the local dependence property and the assumption that \\(\\mathbb{E}(V_{l_1 l_2}) = 0\\). The local dependence property allows us to factor out the expectation of \\(V_{l_1 l_2}\\), as this edge is between neighborhoods, and therefore independent of every other edge in the graph. Now, if we have \\(p = 2\\), then, by sparsity and the fact that the product below is at most \\(1\\), \\[\\begin{equation*} \\mathbb{E}\\left( V_{l_1 l_2}^2\\right) \\mathbb{E}\\left( \\prod_{m,n \\in (i \\cup j) \\setminus \\{l_1, l_2\\}} V_{mn} \\right) \\leq DCn^{-\\delta}, \\end{equation*}\\] where D is a constant that bounds the expectation above. There exists such a constant because each of the V_{mn} are bounded by definiton, so a product of them is bounded. So as \\(K\\) grows large, the between neighborhod covariances all become asymptotically negligible. Therefore, we can conclude that \\[\\begin{equation} \\operatorname{Var}(B^{\\ast}_{K}) = \\sum_{i \\in \\mathcal{N}_{K}^d} \\sum_{j \\in \\mathcal{N}_{K}^d} \\mathbb{I}_{B}(i) \\mathbb{I}_{B}(j) \\operatorname{Cov}(S^{\\ast}_{Ki}, S^{\\ast}_{Kj}) \\leq DCn^{2d(-\\delta)}. \\end{equation}\\] So we have \\[\\begin{equation} \\operatorname{Var}{B^{\\ast}_{K}} \\to 0. \\end{equation}\\] Then, for all \\(\\epsilon &gt; 0\\), Chebyshev’s inequality gives us \\[\\begin{equation} \\lim_{K \\to \\infty} P(|B^{\\ast}_{K}| &gt; \\epsilon) \\leq \\lim_{K \\to \\infty} \\frac{1}{\\epsilon^2} \\operatorname{Var}(B^{\\ast}_{K}) = 0, \\end{equation}\\] so \\[\\begin{equation} B^{\\ast}_{K} \\xrightarrow[K \\to \\infty]{\\text{p}} 0. \\end{equation}\\] Next, we bound the within neighborhood covariances, as we also have \\[\\begin{equation*} \\operatorname{Var}(W^{\\ast}_{Kk}) = \\sum_{i \\in \\mathcal{N}_{K}^d} \\sum_{j \\in \\mathcal{N}_{K}^d} \\mathbb{I}(i, j \\in A_{k}) \\operatorname{Cov}(S^{\\ast}_{Ki}, S^{\\ast}_{Kj}). \\end{equation*}\\] As the covariance forms an inner product on the space of square integrable random variables, the Cauchy-Schwarz inequality gives us \\[\\begin{equation} \\mathbb{I}(i, j \\in A_{k}) \\left| \\operatorname{Cov}(S^{\\ast}_{Ki}, S^{\\ast}_{Kj}) \\right| \\leq \\mathbb{I}(i, j \\in A_{k}) \\sqrt{\\operatorname{Var}(S^{\\ast}_{Ki})} \\sqrt{\\operatorname{Var}(S^{\\ast}_{Kj})}. \\end{equation}\\] Then, as each \\(S^{\\ast}_{Ki}\\) has expectation zero, we know that \\[\\begin{equation} \\operatorname{Var}(S^{\\ast}_{Ki}) = \\mathbb{E}(S^{\\ast 2}_{Ki}) - \\mathbb{E}(S^{\\ast}_{Ki})^2 = \\mathbb{E}(S^{\\ast 2}_{Ki}). \\end{equation}\\] As \\(S^{\\ast 2}_{Ki} \\leq 1\\), we know \\(\\operatorname{Var}(S^{\\ast}_{Ki}) \\leq 1\\) for all tuples \\(i\\), so we have the bound \\[\\begin{equation} \\mathbb{I}(i, j \\in A_{k}) \\left| \\operatorname{Cov}(S^{\\ast}_{Ki}, S^{\\ast}_{Kj}) \\right| \\leq \\mathbb{I}(i, j \\in A_{k}). \\end{equation}\\] Now all that remains is to apply the Lindeberg-Feller central limit theorem to the double sequence \\(W^{\\ast}_{K} = {\\sum_{k = 1}^{K} W^{\\ast}_{K, k}}\\). To that end, first note that, as each neighborhood contains at most a finite number of nodes, \\(M\\), we can show that \\[\\begin{align} \\begin{split} \\operatorname{Var}(W^{\\ast}_{K,k}) &amp;= \\sum_{i \\in \\mathcal{N}_{K}^d} \\sum_{j \\in \\mathcal{N}_{K}^d} \\mathbb{I}(i,j \\in A_k^d) \\operatorname{Cov}(S^{\\ast}_{Ki}, S^{\\ast}_{Kj}) \\\\ &amp;= \\sum_{i \\in \\mathcal{N}_{K}^d} \\sum_{j \\in \\mathcal{N}_{K}^d} \\mathbb{I}(i,j \\in A_k^d) \\mathbb{E}(S^{\\ast}_{Ki} S^{\\ast}_{Kj}) \\\\ &amp;\\leq \\sum_{i \\in \\mathcal{N}_{K}^d} \\sum_{j \\in \\mathcal{N}_{K}^d} 1 \\\\ &amp;\\leq M^{2d}. \\end{split} \\end{align}\\] Now we prove that Lyaponouv’s condition (3.2) holds for the constant in the exponent \\(\\delta = 2\\). So \\[\\begin{align} \\begin{split} \\lim_{K \\to \\infty} \\sum_{k = 1}^{K} \\frac{1}{\\operatorname{Var}(W^{\\ast}_{K})^2} \\mathbb{E}(|W^{\\ast}_{K,k}|^{4}) &amp;= \\lim_{K \\to \\infty} \\frac{1}{\\operatorname{Var}(W^{\\ast}_{K})^2} \\sum_{k = 1}^{K} \\mathbb{E}(W^{\\ast 2}_{K,k}) \\mathbb{E}(W^{\\ast 2}_{K,k}) \\\\ &amp;\\leq \\lim_{K \\to \\infty} \\frac{M^{2d}}{\\operatorname{Var}(W^{\\ast}_{K})^2} \\sum_{k = 1}^{K} \\mathbb{E}(W^{\\ast}_{K,k})^2 \\\\ &amp;= \\lim_{K \\to \\infty} \\frac{M^{2d}}{\\operatorname{Var}(W^{\\ast}_{K})^2} \\sum_{k = 1}^{K} \\operatorname{Var}(W^{\\ast}_{K,k}) \\\\ &amp;= \\lim_{K \\to \\infty} \\frac{M^{2d}}{\\operatorname{Var}(W^{\\ast}_{K})} \\\\ &amp;= 0. \\end{split} \\tag{3.2} \\end{align}\\] where \\(\\operatorname{Var}(W^{\\ast}_{K})\\) tends to infinity by assumption. Therefore, Lyaponouv’s condition holds, and so by the Lindeberg-Feller central limit theorem, we have, \\[\\begin{equation} \\frac{W^{\\ast}_K}{\\sqrt{\\operatorname{Var}(W^{\\ast}_K)}} \\xrightarrow[K \\to \\infty]{\\text{d}} N(0, 1). \\end{equation}\\] Slutsky’s theorem (3.4) gives the final result for \\(S^{\\ast}_{K} = W^{\\ast}_{K} + B^{\\ast}_{K}\\). Then we have \\[\\begin{equation} \\frac{S^{\\ast}_K}{\\sqrt{\\operatorname{Var}(S^{\\ast}_K)}} \\xrightarrow[K \\to \\infty]{\\text{d}} N(0, 1), \\end{equation}\\] as desired. The second class of statistics are those that depend on both the graph and the nodal variates. These have a very similar form as the statistics previously considered. Now we require that \\[\\begin{equation*} S_{K} = \\sum_{i \\in \\mathcal{N}^d} S_{Ki}, \\end{equation*}\\] where \\[\\begin{equation*} S_{Ki} = \\prod_{l,p \\in i} Y_{lp} h(X_l, X_p), \\end{equation*}\\] a product with at most \\(q\\) terms. Theorem 3.8 If \\(S_K\\) is a statistic depending on both the random graph and the random nodal attributes, the sequence of random networks are as before, and the function \\(h\\) is uniformly bounded in the sense that, for all \\(l\\) and \\(m\\), there is some \\(B\\) such that \\[\\begin{equation*} P \\left( |h(X_l, X_m)|^p &gt; B \\right) = 0, \\qquad (p = 1, 2) \\end{equation*}\\] then we also have \\[\\begin{equation*} S_{K} \\xrightarrow[K \\to \\infty]{\\mathrm{d}} N(0,1). \\end{equation*}\\] Proof. This proof is very similar to the proof of Theorem 3.7. We write \\[\\begin{equation*} S_{K} = W{K} + B{K}, \\end{equation*}\\] exactly as before, incorporating the function \\(h\\) into each \\(S_{Ki}\\) as we did above. Then the binary nature of the graph and the uniform boundedness of \\(h\\) allow us to once again recenter the \\(Y_{ij}\\), meaning that we will work with \\(V_{ij}h(X_i, X_j) = Y_{ij}h(X_i, X_j) - \\mu_{ij}\\). We also have \\(\\mathbb{E}(V_{ij} h(X_i, X_j)) = 0\\), so \\(\\mathbb{E}(S^{\\ast}_{Ki}) = 0\\) as well. For the between neighborhood covariances, we once again choose \\(V_{l_1 l_2}\\), a between neighborhood network variable. Then we once again write \\[\\begin{align*} \\operatorname{Cov}(S^{\\ast}_{Ki}, S^{\\ast}_{Kj}) &amp;= \\mathbb{E}\\left( \\prod_{m,n \\in i} V_{mn} h(X_m, X_n) \\prod_{m,n \\in j} V_{mn} h(X_m, X_n) \\right) \\\\ &amp;= \\mathbb{E}\\left( (V_{l_1 l_2} h(X_{l_1}, X_{l_2}))^p \\prod_{m,n \\in (i \\cup j) \\setminus \\{l_1, l_2\\}} V_{mn} h(X_m, X_n) \\right), &amp; (p = 1,2) \\\\ &amp;= \\mathbb{E}\\left( (V_{l_1 l_2} h(X_{l_1}, X_{l_2}))^p \\right) \\mathbb{E} \\left( \\prod_{m,n \\in (i \\cup j) \\setminus \\{l_1, l_2\\}} V_{mn} h(X_m, X_n) \\right), \\end{align*}\\] by the local dependence property. Then, when \\(p = 1\\), we have \\(\\mathbb{E} ( V_{l_1 l_2} h(X_{l_1}, X_{l_2}) ) = 0\\) by assumption, so the covariance is identically zero. When \\(p = 2\\) we have \\[\\begin{equation*} \\mathbb{E}\\left( (V_{l_1 l_2} h(X_{l_1}, X_{l_2}))^2 \\right) \\leq Cn^{-\\delta} \\end{equation*}\\] by sparsity and \\[\\begin{equation*} \\mathbb{E} \\left( \\prod_{m,n \\in (i \\cup j) \\setminus \\{l_1, l_2\\}} V_{mn} h(X_m, X_n) \\right) \\leq (DB)^{2q - 2} \\end{equation*}\\] almost surely by uniform boundedness and the fact this product has at most \\(2q - 2\\) terms. This follows from the fact that \\(h\\) is bounded by \\(B\\) and that \\(V_{mn}\\) is bounded by some constant \\(D\\), by defintion. So \\[\\begin{equation*} \\operatorname{Cov}(S^{\\ast}_{Ki}, S^{\\ast}_{Kj}) \\leq B^{2q - 2}Cn^{-\\delta}, \\end{equation*}\\] which tends to zero as \\(K\\) grows large. So, again by Chebyshev’s inequality, we have \\[\\begin{equation*} B^{\\ast}_{K} \\xrightarrow[K \\to \\infty]{\\mathrm{p}} 0. \\end{equation*}\\] Next we bound the within neighborhood covariances. Now with each \\(|S^{\\ast}_{Ki}| \\leq B^{q}\\), we have \\[\\begin{equation} \\mathbb{I}(i, j \\in A_{k}) \\left| \\operatorname{Cov}(S^{\\ast}_{Ki}, S^{\\ast}_{Kj}) \\right| \\leq \\mathbb{I}(i, j \\in A_{k}) B^{2q}. \\end{equation}\\] Now, we show that Lyaponouv’s condition (3.2) holds for the same \\(\\delta = 2\\). Once again note that each neighborhood has at most \\(M\\) nodes, so \\[\\begin{align*} \\operatorname{Var}(W^{\\ast}_{K,k}) &amp;= \\sum_{i \\in \\mathcal{N}_{K}^d} \\sum_{j \\in \\mathcal{N}_{K}^d} \\mathbb{I}(i,j \\in A_{k}) \\operatorname{Cov}(S^{\\ast}_{Ki}, S^{\\ast}_{Kj}) \\\\ &amp;\\leq \\sum_{i \\in \\mathcal{N}_{K}^d} \\sum_{j \\in \\mathcal{N}_{K}^d} \\mathbb{I}(i,j \\in A_{k}) B^{2q} \\\\ &amp;\\leq M^{2d}B^{2q}. \\end{align*}\\] Then Lyaponouv’s condition is \\[\\begin{align} \\begin{split} \\lim_{K \\to \\infty} \\sum_{k = 1}^{K} \\frac{1}{\\operatorname{Var}(W^{\\ast}_{K})^2} \\mathbb{E}(|W^{\\ast}_{K,k}|^{4}) &amp;= \\lim_{K \\to \\infty} \\frac{1}{\\operatorname{Var}(W^{\\ast}_{K})^2} \\sum_{k = 1}^{K} \\mathbb{E}(W^{\\ast 2}_{K,k}) \\mathbb{E}(W^{\\ast 2}_{K,k}) \\\\ &amp;\\leq \\lim_{K \\to \\infty} \\frac{M^{2d}B^{2q}}{\\operatorname{Var}(W^{\\ast}_{K})^2} \\sum_{k = 1}^{K} \\mathbb{E}(W^{\\ast 2}_{K,k}) \\\\ &amp;= \\lim_{K \\to \\infty} \\frac{M^{2d}B^{2q}}{\\operatorname{Var}(W^{\\ast}_{K})^2} \\sum_{k = 1}^{K} \\operatorname{Var}(W^{\\ast}_{K,k}) \\\\ &amp;= \\lim_{K \\to \\infty} \\frac{M^{2d}B^{2q}}{\\operatorname{Var}(W^{\\ast}_{K})} \\label{eq:Lya} \\\\ &amp;= 0. \\end{split} \\end{align}\\] Therefore, by the Lindeberg-Feller central limit theorem and Slutsky’s theorem, we have \\[\\begin{equation*} \\frac{S_{K}^{\\ast}}{\\sqrt{\\operatorname{Var}(S_{K}^{\\ast})}} \\xrightarrow[K \\to \\infty]{\\mathrm{d}} N(0,1).\\qedhere \\end{equation*}\\] Finally, the last class of statistic is that which depends only on the nodal variates. This result follows directly from a central limit theorem for \\(M\\)-dependent random variables, which can be found in Billingsley (1995, p. 364). Establishing this theorem requires that we assume that the statistic in question depends only on a single variable across nodes. Therefore we assume that the statistic depends only on a single nodal covariate. Theorem 3.9 Take the sequence \\(Z_{K}\\) as before, and let \\(X_K\\) be the vector of nodal variates for each \\(Z_{K}\\). Call each entry of this vector \\(X_{Ki}\\), the variate corresponding to node \\(i\\). Furthermore, we assume that \\(\\mathbb{E}(X_{Ki}^{12}) &lt; \\infty\\), \\(\\mathbb{E}(X_{Ki} = 0)\\). Then, \\[\\begin{equation*} \\lim_{K \\to \\infty}\\frac{\\operatorname{Var}(\\sum_{i= 1}^{n} X_{Ki})}{n} = \\sigma^2, \\end{equation*}\\] where \\(n = |\\mathcal{N}|\\). Furthermore, if \\(\\sigma &gt; 0\\), then \\[\\begin{equation*} \\frac{\\sum_{i = 1}^{n} X_{Ki}}{\\sqrt{n \\operatorname{Var}(\\sum_{i= 1}^{n} X_{Ki})}} \\xrightarrow[K \\to \\infty]{\\mathrm{d}} N(0,1). \\end{equation*}\\] Proof. Two random variables \\(X_{Kl}\\) and \\(X_{Kp}\\) are dependent if and only if \\(l\\) and \\(p\\) are in the same neighborhood. Without loss of generality, assume that the neighborhoods are such that all nodes within a neighborhood are indexed by consecutive integers. Then let \\(M = \\limsup |A_{K}|\\). Then the sequence \\(X_{Kl}\\) is \\(M\\)-dependent, so the result follows by application of Theorem 27.4 in Billingsley (1995). In practice, the hypothesis that the twelfth moment exists is satisfied for most reasonable distributional assumptions about nodal covariates. Furthermore, the assumption that all nodal variates have expectation zero can easily be satisfied by recentering the observed data. Finally, the delta method gives us an asymptotically normal distribution for a differentiable statistic of the nodal variate. The univariate nature of the statistic is a fundamental limitation of this approach, however I am unable to find an analogous multidimensional central limit theorem that would allow us to establish the asymptotic normality of a statistic of multiple nodal variates. References "],
["4-discussion-and-examples.html", "Chapter 4 Discussion and examples 4.1 Examples of convergence 4.2 Standard error estimation 4.3 Discussion of future work", " Chapter 4 Discussion and examples 4.1 Examples of convergence In this section we simulate locally dependent random networks and calculate a statistic from each class discussed in Chapter 3. These networks grow larger and larger throughout the simulation, with each having \\(n\\) vertices and \\(n/10\\) neighborhoods, to explore the asymptotic properties of our statistics. The nodes have two attributes. The first is a group, coded as \\(0\\) or \\(1\\), that effects the network formation. Edges are more likely to form between vertices in the same group. The second is a random attribute, also coded as \\(0\\) or \\(1\\). For each vertex, the value of this attribute depends on the attributes of the other vertices that it is connected to. The attribute can be thought of as a contagious infection or behavior that spreads along edges of the graph. The C++ and R code used to generate these networks is shown in section A.1. This sort of complex relationship between the vertices and the edges is exactly the kind of generative process that ERNMs hope to capture. Figure 4.1 shows an illustration of a simulated network with 100 vertices. The coloring shows the neighborhood membership of each vertex, while the presence or absence of fill indicates the value of the simulated attribute. Note the clustering of the neighborhoods and the attribute values. This is exactly the kind of joint clustering the locally dependent ERNM models. Furthermore, this also makes very intuitive sense as a realistic network structure. For example, suppose the attribute we are considering is smoking. This network shows that people who are friends with smokers are more likely to smoke themselves. This was the analysis done by Fellows &amp; Handcock (2012) when introducing the ERNM. Adding local dependence to this model is what allows us to show central limit theorems, however. In Figures 4.2 and 4.3, we can see the desired convergence towards a normal distribution that is guaranteed by the theorems proved in Chapter 3. In Figure 4.3, the quantile-quantile plots become very linear when the number of nodes reaches 200 and the number of neighborhoods reaches 20. All of the skewness has disappeared by this point and the tails of the distributions are almost perfectly normal. Finally, note that the slope is becoming shallower as the number of vertices grows. This corresponds to the shrinking of the statistic’s variance, which is exactly what we hope to see as we grow the sample size. Figure 4.1: A simulated network with 100 vertices, colored according to neighborhood. The vertex fill indicates the presence or absence of the simulated attribute. Figure 4.2: Density plots of simulated statistics of locally dependent random networks. Figure 4.3: Normal Q-Q plots for simulated statistics of locally dependent random networks. 4.2 Standard error estimation Given the asymptotic normality, all that remains to make these theorems useful for inference is to find a method to estimate the standard error of a statistic from a single observation. To that end, here we simulate a single network with 200 vertices by the same procedure as above and attempt to recover the standard errors of the statistics. We can compare these estimates to the standard errors of the empirical distributions we found in our previous simulation. There are several approaches to approximating the standard errors. The first is to follow the vertex-level jackknife procedure outlined by Snijders &amp; Borgatti (1999). This method is a modification of the standard jackknife estimator of standard deviation. At each iteration of the procedure, we remove one vertex from the network and recalculate the statistics of interest. Then we estimate the standard error with the equation \\[\\begin{equation} \\widehat{\\text{s.e.}} = \\sqrt{\\frac{n - 2}{2n} \\sum_{i = 1}^{n} (g_{-i} - \\bar{g})^2}, \\end{equation}\\] where \\(g\\) is the quantity whose standard error we are approximating and \\(g_{-i}\\) is \\(g\\) calculated with vertex \\(i\\) removed. This differs from the standard jackknife estimator in the multiplicative constant. Heuristically, this constant accounts for the fact that we are seeing much less variation in the jackknife networks than we would expect to see in the true distribution. This follows from the fact that the variance of a statistic of the edge variables is (approximately) inversely proportional to the number of edge variables, \\(n(n-1)\\), not the number of vertices, \\(n\\) (Snijders &amp; Borgatti, 1999). We can see in Table 4.1 that this procedure underestimates the variance of our statistics. Table 4.1: Standard error estimates using the jackknife at the vertex level. Statistic Simulated standard error Jackknife standard error % Attribute 0.0647304 0.0242058 Mean degree 1.1011253 0.8231390 % Hom. ties 0.0271141 0.0185213 Table 4.2: Standard error estimates using the jackknife at the neighborhood level. Statistic Simulated standard error Jackknife standard error % Attribute 0.0647304 0.0687571 Mean degree 1.1011253 1.6604948 % Hom. ties 0.0271141 0.0249828 This is most likely because of the dependence between vertices in the process that generated the network. The second method is a standard jackknife, but leverages the neighborhood structure and the local dependence of the network. We do this by applying the jackknife at the level of the neighborhoods. That is to say, we remove each neighborhood in turn and recompute the statistic and then compute the jackknife estimator \\[\\begin{equation} \\widehat{\\text{s.e.}} = \\sqrt{\\frac{m-1}{m} \\sum_{i = 1}^m (g_{-i} - \\bar{g})^2}, \\end{equation}\\] where \\(m\\) is the number of neighborhoods. This process gives much more appropriate estimates, shown in Table 4.2. 4.3 Discussion of future work Further development of locally dependent ERNMs for modelling complex social processes will have major impacts in the social sciences. The most pressing issue is the creation of software that allows for estimating parameters in these models. Code for fitting locally dependent ERGMs was developed by Schweinberger &amp; Handcock (2015) and a Markov chain Monte Carlo algorithm for ERNMs was implemented by Fellows &amp; Handcock (2012). However, it still remains to combine these two developments to work with locally dependent ERNMs. Further mathematical work is also required to extend Theorem 3.9 to statistics involving more than one vertex attribute. This proof requires a multivariate analogue of the central limit theorem for \\(M\\)-dependent random variables. As my adviser told me, where there is a univariate central limit theorem, there is invariably a corresponding multidimensional theorem. However, we are unable to find a proof of this, so that result must be the topic of future work. Finally, an investigation into the properties of standard error estimates like those produced above is much needed. Network sample sizes tend to be relatively small, so being forced to aggregate at the neighborhood level is a nontrivial issue. Furthermore, the jackknife procedure is most likely not making full use of all the information available within the observed network. However, a bootstrap procedure is, as far as my research shows, undefined for network data. Difficulty comes from being unable to sample with replacement. If one were to sample a network’s vertices or edges with replacement, most likely duplicate edges would appear in the resampled networks. It is unclear how duplicates should be handled when calculating network statistics, so that sort of procedure is difficult to define. References "],
["A-code.html", "A Code A.1 Network simulation code A.2 Jackknife standard error code", " A Code All source materials used to write this thesis are available in the Reed College Library’s digital thesis archive. This appendix contains the most important code used in the final chapter. A.1 Network simulation code if(!require(devtools)) install.packages(&quot;devtools&quot;, repos = &quot;http://cran.rstudio.com&quot;) if(!require(thesisdown)) devtools::install_github(&quot;ismayc/thesisdown&quot;) library(thesisdown) library(statnet) library(Bergm) library(tidyverse) library(broom) library(ggraph) library(purrr) library(Rcpp) library(knitr) The following C++ code, compiled into a shared library using the Rcpp package, gives function definitions used in simulating networks (Eddelbuettel &amp; Francois, 2011). #include &lt;Rcpp.h&gt; using namespace Rcpp; //[[Rcpp::export]] IntegerMatrix make_adj(List vert_df){ NumericVector vert = vert_df[&quot;vert&quot;]; NumericVector nbhd = vert_df[&quot;nbhd&quot;]; NumericVector grp = vert_df[&quot;grp&quot;]; double n = vert.size(); IntegerMatrix adj_mat(n,n); for(int i = 0; i &lt; n; i++){ for(int j = 0; j &lt; n; j++){ if(nbhd[i] == nbhd[j]){ if(grp[i] == grp[j]){ adj_mat(i,j) = as&lt;int&gt;(rbinom(1,1,.3)); continue; } else { adj_mat(i,j) = as&lt;int&gt;(rbinom(1, 1, .1)); continue; } } else{ adj_mat(i,j) = as&lt;int&gt;(rbinom(1, 1, 50/(n*n))); continue; } } } for(int i = 1; i &lt; n/10; i++){ for(int j = 0; j &lt; n; j++){ for(int k = 0; k &lt; n; k++){ for(int l = 0; l &lt; n; l++){ if(nbhd[j] == i &amp;&amp; nbhd[k] == i &amp;&amp; nbhd[l] == i){ if(adj_mat(j, k) == 1 &amp;&amp; adj_mat(k, l) == 1 &amp;&amp; adj_mat(j, l) == 0){ adj_mat(j, l) = as&lt;int&gt;(rbinom(1, 1, .75)); } } } } } } return adj_mat; } //[[Rcpp::export]] IntegerVector make_attr(List vert_df, IntegerMatrix adj_mat){ IntegerVector attr = vert_df[&quot;attr&quot;]; IntegerVector nbhd = vert_df[&quot;nbhd&quot;]; int n = attr.size(); for(int i = 0; i &lt; n; i++){ for(int j = 0; j &lt; n; j++){ if(attr[i] == 1 &amp;&amp; adj_mat(i,j) == 1 &amp;&amp; nbhd[i] == nbhd[j]){ attr[j] = as&lt;int&gt;(rbinom(1, 1, .75)); }else if(adj_mat(i,j) == 1 &amp;&amp; nbhd[i] == nbhd[j]){ attr[j] = as&lt;int&gt;(rbinom(1, 1, .1)); } } } return attr; } This R code generates networks and computes the three chosen statistics for each one. The final result is a data set of networks and corresponding statistics used to produce density and quantile-quantile plots. make_net &lt;- function(n){ vert_df &lt;- tibble(vert = 1:n) nbhds &lt;- 1:floor(n/10) vert_df &lt;- vert_df %&gt;% mutate(nbhd = sample(nbhds, n, replace = TRUE), grp = rbinom(n, 1, .5), attr = rbinom(n, 1, .3)) adj_mat &lt;- make_adj(vert_df) vert_df$attr &lt;- make_attr(vert_df, adj_mat) net &lt;- network(adj_mat) net %v% &quot;group&quot; &lt;- vert_df$grp net %v% &quot;attribute&quot; &lt;- vert_df$attr net %v% &quot;nbhd&quot; &lt;- vert_df$nbhd return(net) } node_match &lt;- function(net){ edge_list &lt;- as.edgelist(net) grps &lt;- net %v% &quot;group&quot; num &lt;- 0 for(i in 1:nrow(edge_list)){ if(grps[edge_list[i, 1]] == grps[edge_list[i,2]]) num &lt;- num + 1 } num/nrow(edge_list) } n_reps &lt;- 500 results &lt;- tibble(num = c(rep(20, n_reps), rep(50, n_reps), rep(100, n_reps), rep(200, n_reps))) results &lt;- results %&gt;% mutate(net = map(num, make_net), mean_deg = map_dbl(net, ~ mean(degree(.x))), mean_attr = map_dbl(net, ~ mean(.x %v% &quot;attribute&quot;)), prop_homo = map_dbl(net, node_match)) results &lt;- results %&gt;% gather(stat, value, -(num:net)) A.2 Jackknife standard error code This code computes the neighborhood level standard error estimates for statistics of the graph. n_vert &lt;- 200 net &lt;- make_net(n_vert) nbhds &lt;- net %v% &quot;nbhd&quot; num_nbhds &lt;- length(unique(nbhds)) boot3 &lt;- numeric(num_nbhds) jack_df &lt;- tibble(mean_deg = numeric(num_nbhds), mean_attr = numeric(num_nbhds), prop_homo = numeric(num_nbhds)) for(i in 1:num_nbhds){ temp_net &lt;- rm_vertex(net, which(nbhds == i)) jack_df$mean_deg[i] &lt;- mean(degree(temp_net)) jack_df$mean_attr[i] &lt;- mean(temp_net %v% &quot;attribute&quot;) jack_df$prop_homo[i] &lt;- node_match(temp_net) } jack_df &lt;- jack_df %&gt;% gather(stat, value) %&gt;% group_by(stat) %&gt;% summarise(jack_sd = sqrt((num_nbhds - 1)/num_nbhds * sum((value - mean(value))^2))) References "],
["references.html", "References", " References "]
]
